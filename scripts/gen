#! /usr/bin/env python3

import argparse
import os
import readline
from sys import excepthook
import time
from proto.enums import EnumRule
from rich.console import Console
from rich.markdown import Markdown
from rich.prompt import Prompt
from rich.live import Live
from rich.progress import Progress
from rich import print

GOOGLE_API_KEY=os.getenv('GOOGLE_API_KEY')

# TODO: 1. handle inline input from vim
# TODO: 2. handle multiline strings in the form of """


# we don't need these
safety_settings = [
    {
        "category": "HARM_CATEGORY_DANGEROUS",
        "threshold": "BLOCK_NONE",
    },
    {
        "category": "HARM_CATEGORY_HARASSMENT",
        "threshold": "BLOCK_NONE",
    },
    {
        "category": "HARM_CATEGORY_HATE_SPEECH",
        "threshold": "BLOCK_NONE",
    },
    {
        "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
        "threshold": "BLOCK_NONE",
    },
    {
        "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
        "threshold": "BLOCK_NONE",
    },
]


parser = argparse.ArgumentParser(description="A generative chatbot using the Gemini API. The api output is streamed and the resulting text is printed as rendered markdown in the terminal. The chat is all saved in ~/.chat.md. Multi-lined input is triggered by adding a triple quote \"\"\" which is first replaced by a newline, then this multilined mode is ended by just passing another tripple quote (nothing else!). See the other options below")

# Add the optional stream argument
parser.add_argument('-r', '--raw', 
                action='store_true',
                help='print the raw text without rendering markdown')

parser.add_argument('-f', '--file', 
                help="read in a text file.")

parser.add_argument('-p', '--prompt', 
                help="prompt mode for inline vim editing")

# Parse the arguments
args = parser.parse_args()

with Progress(transient=True) as progress:
    task = progress.add_task("Loading", total=None)
    import google.generativeai as genai

    genai.configure(api_key=GOOGLE_API_KEY)

    console = Console()
    model = genai.GenerativeModel('gemini-1.5-flash-latest', safety_settings=safety_settings)
    chat = model.start_chat()

def get_input(pre_prompt="Prompt"):
    """
    Get user prompt and preprocess.
    If the user types the word 'file', then
    we invoke a file reading subroutine
    """
    global console
    while True:
        p = input(f'{pre_prompt}: ')
        if p == "":
            continue
        elif p == "exit":
            exit(0)
        elif p == "file":
            while True:
                filename = input("Enter a filename: ")
                try:
                    with open(filename, 'r') as f:
                        fc = f.read()
                        break
                except Exception as e:
                    print(e)
                    continue

            preamble = input("Preamble prompt: ")
            p = preamble + "\n\n" + fc
        elif '"""' in p :
            p = p.replace('"""','\n')
            multiline_input = []
            while True:
                line = input("> ")
                if line == '"""':
                    break
                multiline_input.append(line)
            p += '\n'.join(multiline_input)
        break
    return p

# def raw_response_stream(console, response):
#     md_content = ""
#     for chunk in response:
#         words = chunk.text.split(' ')
#         for i, word in enumerate(words):
#             if i < len(words)-1:
#                 md_content += word + ' '
#             else:
#                 md_content += word
#             print(md_content, end='')
#             # markdown = Markdown(md_content)
#             # time.sleep(0.01)
#             # live.update(markdown, refresh=True)
#     return md_content


def live_response_md_stream(console, response):
    md_content = ""
    with Live(console=console, auto_refresh=False) as live:
        for chunk in response:
            words = chunk.text.split(' ')
            for i, word in enumerate(words):
                if i < len(words)-1:
                    md_content += word + ' '
                else:
                    md_content += word
                markdown = Markdown(md_content)
                time.sleep(0.01)
                live.update(markdown, refresh=True)
    return md_content

def truncate_string(s, length):
    return s[:length]+"..." if len(s) > length else s

# TODO: handle file input 
if args.file:
    p = get_input("Enter a preamble prompt before file")

    with open(args.file, 'r') as f:
        fc = f.read()

    p += fc
    response = chat.send_message(p, stream=True)
    live_response_md_stream(console, response)

console.rule("", style="bold blue")

with open(os.path.expanduser('~') + '/.chat.md', 'a') as chat_log:
    while True:
        try:
            p = get_input()
            resp = ""
            response = chat.send_message(p, stream=True)
            md_content = ""
            console.rule("", style="bold green")

            # print the raw text (with typing animations)
            if args.raw:
                for chunk in response:
                    resp += chunk.text
                    words = chunk.text.split(' ')
                    for i, word in enumerate(words):
                        if i < len(words) - 1:
                            print(word, end=' ', flush=True)
                        else:
                            print(word, end='')
                        time.sleep(0.01)
                print()

            # print the neat markdown version
            else:
                resp = live_response_md_stream(console, response)


        except KeyboardInterrupt:
            # print(":warning-emoji: [bold red blink] KeyboardInterrupt! TOOD fix this[/]")
            # exit(1)
            print()
            continue
        except EOFError:
            print(":warning-emoji: [bold red blink] KeyboardInterrupt! TOOD fix this[/]")
            exit(0)

        except Exception as e:
            print(e)
            print(":warning-emoji: [bold red blink] Response failed![/]")
            exit(1)

        chat_log.write("prompt: " + truncate_string(p, 50) + '\n\n' + 80*'-' + '\n')
        chat_log.write(resp + '\n\n' + 80*'-' + '\n\n')

        console.rule("", style="bold blue")
